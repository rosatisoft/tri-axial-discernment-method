# Example â€” AI Efficiency & Engineering
# Case: Training on Full Dataset

## Claim Evaluated
â€œTraining the model on the full dataset guarantees best accuracy at no cost.â€

## FUNDAMENTO (F)
Empirical support: Weak
Contradictions: Common (overfitting)
Source expert: No
Assumptions required: Many
Historical benchmarks: Against claim

F = (0.4 + 0.3 + 0.2 + 0.3 + 0.4) / 5 â‰ˆ **0.32**

## CONTEXTO (C)
Motivation: Pressure for max score
Resource real cost: Ignored
External forces: Yes (delivery deadlines)
Emotional/political influence: Medium
Contextual fit: Weak

C = (0.6 + 0.4 + 0.6 + 0.5 + 0.4) / 5 â‰ˆ **0.50**

## PRINCIPIO (P)
Entropy reduction: No (higher compute)
Sustainability: Poor
Human wellbeing: Risk (burnout)
Constructive path: Partial (subsetting possible)
Alignment with coherence: Medium-low

P = (0.4 + 0.3 + 0.5 + 0.6 + 0.5) / 5 â‰ˆ **0.46**

## FINAL SCORE
D = (0.32 + 0.50 + 0.46) / 3 â‰ˆ **0.43**

## Action
ğŸ‘‰ â€œQuestion and correctâ€
Use smart sampling
Tune hyperparameters
Reduce training cycles
Document energy savings

## Summary
â€œMore data is not always more truth. Coherence beats brute force.â€
